{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install speechrecognition\n",
        "!pip install pandas\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ztKbqwpnUlJf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1804cb9-d4fd-4561-fdd6-7c7af0a2ddba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting speechrecognition\n",
            "  Downloading SpeechRecognition-3.10.0-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from speechrecognition) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->speechrecognition) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->speechrecognition) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->speechrecognition) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->speechrecognition) (2023.7.22)\n",
            "Installing collected packages: speechrecognition\n",
            "Successfully installed speechrecognition-3.10.0\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PyJKnUniVFn",
        "outputId": "6ad50314-19f7-4079-9966-edc5d2769605"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.0.2+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (17.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U openai-whisper\n",
        "!pip install transformers==4.30.0"
      ],
      "metadata": {
        "id": "ivF_MM9mVE6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d74ec38b-61c9-4832-f0c9-f15aa75d1a73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20230918.tar.gz (794 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m794.3/794.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.0.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.56.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.1.0)\n",
            "Collecting tiktoken==0.3.3 (from openai-whisper)\n",
            "  Downloading tiktoken-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.3->openai-whisper) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.3->openai-whisper) (2.31.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (3.27.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (3.12.4)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (17.0.2)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20230918-py3-none-any.whl size=798399 sha256=0c56d6d81dfeb6cf06d337b2892aa653efde170fae0008717fba301a11c654bb\n",
            "  Stored in directory: /root/.cache/pip/wheels/5d/37/b1/9aea93201fe91e3561719120da92cc23e77b7ef6f3d0d9491a\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: tiktoken, openai-whisper\n",
            "Successfully installed openai-whisper-20230918 tiktoken-0.3.3\n",
            "Collecting transformers==4.30.0\n",
            "  Downloading transformers-4.30.0-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (3.12.4)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers==4.30.0)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.30.0)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers==4.30.0)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.0) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.0) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.0) (2023.7.22)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.13.3 transformers-4.30.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "G0lREPMaUSof",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef3e0c8f-c0bb-4ee8-9993-b11ae994536d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " I love the color and the performance is very first.\n",
            "Transcription appended to 'input.csv'\n",
            "                                          Statements\n",
            "0   I love the color and the performance is very ...\n",
            "1   I love the color and the performance is very ...\n",
            "Classification results appended to 'output.csv'\n",
            "\n",
            "Statement 1:  I love the color and the performance is very first.\n",
            "Emotions:\n",
            "love: 0.9215\n",
            "admiration: 0.0835\n",
            "approval: 0.0311\n",
            "neutral: 0.0208\n",
            "joy: 0.0141\n",
            "\n",
            "Statement 2:  I love the color and the performance is very first.\n",
            "Emotions:\n",
            "love: 0.9215\n",
            "admiration: 0.0835\n",
            "approval: 0.0311\n",
            "neutral: 0.0208\n",
            "joy: 0.0141\n"
          ]
        }
      ],
      "source": [
        "import speech_recognition as sr\n",
        "import pandas as pd\n",
        "from transformers import pipeline\n",
        "\n",
        "# Initialize the recognizer\n",
        "recognizer = sr.Recognizer()\n",
        "import whisper\n",
        "\n",
        "audio_file = \"audio.wav\"\n",
        "model = whisper.load_model(\"base\")\n",
        "result = model.transcribe(audio_file, fp16=False)\n",
        "print(result[\"text\"])\n",
        "text = result[\"text\"]\n",
        "try:\n",
        "    df = pd.read_csv(\"input.csv\")\n",
        "except FileNotFoundError:\n",
        "    df = pd.DataFrame(columns=[\"Statements\"])\n",
        "\n",
        "# Append the new transcription to the DataFrame\n",
        "df = df._append({\"Statements\": text}, ignore_index=True)\n",
        "\n",
        "# Save the updated DataFrame to the CSV file in append mode\n",
        "df.to_csv(\"input.csv\", mode='a', header=True, index=False)\n",
        "print(\"Transcription appended to 'input.csv'\")\n",
        "\n",
        "# Now, use the machine learning model to classify the text from the CSV file\n",
        "classifier = pipeline(task=\"text-classification\", model=\"SamLowe/roberta-base-go_emotions\", top_k=5)\n",
        "print(df)\n",
        "# Process the text from the CSV file\n",
        "model_outputs = classifier(df[\"Statements\"].tolist())\n",
        "\n",
        "\n",
        "# Create a new DataFrame to store the scores\n",
        "scores_df = pd.DataFrame(model_outputs)\n",
        "\n",
        "# Concatenate the original DataFrame with the scores DataFrame\n",
        "result_df = pd.concat([df, scores_df], axis=1)\n",
        "\n",
        "# Save the result to a new CSV file in append mode\n",
        "result_df.to_csv('output.csv', mode='a', header=True, index=False)\n",
        "print(\"Classification results appended to 'output.csv'\")\n",
        "\n",
        "# Print the classification results\n",
        "for i, row in result_df.iterrows():\n",
        "    statement = row['Statements']\n",
        "    print(f\"\\nStatement {i + 1}: {statement}\")\n",
        "\n",
        "    print(\"Emotions:\")\n",
        "    for col_idx in range(5):\n",
        "        emotion_info = row[col_idx]\n",
        "        label = emotion_info['label']\n",
        "        score = emotion_info['score']\n",
        "        print(f\"{label}: {score:.4f}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyabsa==1.15.5"
      ],
      "metadata": {
        "id": "_yk-9oKrz0kW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1abf5a59-a095-46fd-aa90-4e7884c88c1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyabsa==1.15.5\n",
            "  Downloading pyabsa-1.15.5-py3-none-any.whl (248 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/248.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m174.1/248.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.0/248.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting findfile>=1.7.9.3 (from pyabsa==1.15.5)\n",
            "  Downloading findfile-2.0.0-py3-none-any.whl (9.3 kB)\n",
            "Collecting autocuda>=0.11 (from pyabsa==1.15.5)\n",
            "  Downloading autocuda-0.16-py3-none-any.whl (5.1 kB)\n",
            "Collecting metric-visualizer>=0.4.22 (from pyabsa==1.15.5)\n",
            "  Downloading metric_visualizer-0.9.9-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from pyabsa==1.15.5) (3.6.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pyabsa==1.15.5) (3.1)\n",
            "Collecting seqeval (from pyabsa==1.15.5)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting update-checker (from pyabsa==1.15.5)\n",
            "  Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pyabsa==1.15.5) (4.5.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pyabsa==1.15.5) (4.66.1)\n",
            "Collecting pytorch-warmup (from pyabsa==1.15.5)\n",
            "  Downloading pytorch_warmup-0.1.1-py3-none-any.whl (6.6 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from pyabsa==1.15.5) (2.3.0)\n",
            "Collecting gitpython (from pyabsa==1.15.5)\n",
            "  Downloading GitPython-3.1.37-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.0/190.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gdown>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pyabsa==1.15.5) (4.6.6)\n",
            "Collecting transformers>4.20.0 (from pyabsa==1.15.5)\n",
            "  Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>1.0.0 in /usr/local/lib/python3.10/dist-packages (from pyabsa==1.15.5) (2.0.1+cu118)\n",
            "Collecting sentencepiece (from pyabsa==1.15.5)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=4.4.0->pyabsa==1.15.5) (3.12.4)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown>=4.4.0->pyabsa==1.15.5) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown>=4.4.0->pyabsa==1.15.5) (1.16.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.4.0->pyabsa==1.15.5) (4.11.2)\n",
            "Requirement already satisfied: matplotlib>=3.6.3 in /usr/local/lib/python3.10/dist-packages (from metric-visualizer>=0.4.22->pyabsa==1.15.5) (3.7.1)\n",
            "Collecting tikzplotlib (from metric-visualizer>=0.4.22->pyabsa==1.15.5)\n",
            "  Downloading tikzplotlib-0.10.1-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.2/54.2 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from metric-visualizer>=0.4.22->pyabsa==1.15.5) (1.11.3)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from metric-visualizer>=0.4.22->pyabsa==1.15.5) (0.9.0)\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.10/dist-packages (from metric-visualizer>=0.4.22->pyabsa==1.15.5) (8.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from metric-visualizer>=0.4.22->pyabsa==1.15.5) (1.23.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from metric-visualizer>=0.4.22->pyabsa==1.15.5) (8.1.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from metric-visualizer>=0.4.22->pyabsa==1.15.5) (1.5.3)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (from metric-visualizer>=0.4.22->pyabsa==1.15.5) (3.1.2)\n",
            "Collecting xlsxwriter (from metric-visualizer>=0.4.22->pyabsa==1.15.5)\n",
            "  Downloading XlsxWriter-3.1.6-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.3/154.3 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy>=1.10.0 (from metric-visualizer>=0.4.22->pyabsa==1.15.5)\n",
            "  Downloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn<1.3.0 in /usr/local/lib/python3.10/dist-packages (from metric-visualizer>=0.4.22->pyabsa==1.15.5) (1.2.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>1.0.0->pyabsa==1.15.5) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>1.0.0->pyabsa==1.15.5) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>1.0.0->pyabsa==1.15.5) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>1.0.0->pyabsa==1.15.5) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>1.0.0->pyabsa==1.15.5) (17.0.2)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers>4.20.0->pyabsa==1.15.5)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>4.20.0->pyabsa==1.15.5) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>4.20.0->pyabsa==1.15.5) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>4.20.0->pyabsa==1.15.5) (2023.6.3)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers>4.20.0->pyabsa==1.15.5)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers>4.20.0->pyabsa==1.15.5)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1 (from gitpython->pyabsa==1.15.5)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->pyabsa==1.15.5) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->pyabsa==1.15.5) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->pyabsa==1.15.5) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->pyabsa==1.15.5) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->pyabsa==1.15.5) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy->pyabsa==1.15.5) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->pyabsa==1.15.5) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->pyabsa==1.15.5) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->pyabsa==1.15.5) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->pyabsa==1.15.5) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy->pyabsa==1.15.5) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy->pyabsa==1.15.5) (6.4.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->pyabsa==1.15.5) (1.10.13)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy->pyabsa==1.15.5) (67.7.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->pyabsa==1.15.5) (3.3.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython->pyabsa==1.15.5)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers>4.20.0->pyabsa==1.15.5) (2023.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.3->metric-visualizer>=0.4.22->pyabsa==1.15.5) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.3->metric-visualizer>=0.4.22->pyabsa==1.15.5) (0.12.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.3->metric-visualizer>=0.4.22->pyabsa==1.15.5) (4.43.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.3->metric-visualizer>=0.4.22->pyabsa==1.15.5) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.3->metric-visualizer>=0.4.22->pyabsa==1.15.5) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.3->metric-visualizer>=0.4.22->pyabsa==1.15.5) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.3->metric-visualizer>=0.4.22->pyabsa==1.15.5) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=4.4.0->pyabsa==1.15.5) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=4.4.0->pyabsa==1.15.5) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=4.4.0->pyabsa==1.15.5) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=4.4.0->pyabsa==1.15.5) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.3.0->metric-visualizer>=0.4.22->pyabsa==1.15.5) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.3.0->metric-visualizer>=0.4.22->pyabsa==1.15.5) (3.2.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy->pyabsa==1.15.5) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy->pyabsa==1.15.5) (0.1.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.4.0->pyabsa==1.15.5) (2.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>1.0.0->pyabsa==1.15.5) (2.1.3)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl->metric-visualizer>=0.4.22->pyabsa==1.15.5) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->metric-visualizer>=0.4.22->pyabsa==1.15.5) (2023.3.post1)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=4.4.0->pyabsa==1.15.5) (1.7.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>1.0.0->pyabsa==1.15.5) (1.3.0)\n",
            "Requirement already satisfied: webcolors in /usr/local/lib/python3.10/dist-packages (from tikzplotlib->metric-visualizer>=0.4.22->pyabsa==1.15.5) (1.13)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=771fe3666e58e2343196b8621d4a107d82a111a88a1436f0506ff9cb0484dfa9\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built seqeval\n",
            "Installing collected packages: sentencepiece, xlsxwriter, smmap, scipy, safetensors, findfile, autocuda, update-checker, huggingface-hub, gitdb, tokenizers, tikzplotlib, seqeval, gitpython, transformers, metric-visualizer, pytorch-warmup, pyabsa\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.11.3\n",
            "    Uninstalling scipy-1.11.3:\n",
            "      Successfully uninstalled scipy-1.11.3\n",
            "Successfully installed autocuda-0.16 findfile-2.0.0 gitdb-4.0.10 gitpython-3.1.37 huggingface-hub-0.17.3 metric-visualizer-0.9.9 pyabsa-1.15.5 pytorch-warmup-0.1.1 safetensors-0.4.0 scipy-1.10.1 sentencepiece-0.1.99 seqeval-1.2.2 smmap-5.0.1 tikzplotlib-0.10.1 tokenizers-0.14.1 transformers-4.34.0 update-checker-0.18.0 xlsxwriter-3.1.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyabsa import available_checkpoints\n",
        "checkpoint_map = available_checkpoints(from_local=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYyZSavgz0cO",
        "outputId": "d588c457-5e65-4dc1-9e27-c2b33a512af6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No CUDA GPU found in your device\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Remote ABSADataset version: 2022.10.25 Local ABSADatasets version: None\n",
            "Unknown local version for ABSADatasets, please check the latest version of ABSADatasets at https://github.com/yangheng95/ABSADatasets\n",
            "Version 1.15.5 of pyabsa is outdated. Version 2.3.3 was released Friday August 11, 2023.\n",
            "check release notes at https://github.com/yangheng95/PyABSA/blob/release/release-note.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1CBVGPA3xdQqdkFFwzO5T2Q4reFtzFIJZ\n",
            "To: /content/checkpoints.json\n",
            "100%|██████████| 8.17k/8.17k [00:00<00:00, 5.80MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********** Available APC model checkpoints for Version:1.15.5 (this version) **********\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Checkpoint Name: english\n",
            "id: https://drive.google.com/file/d/1JIFhaAdoCeZI5CQqfOix3pnrYa6_Mf9S/view?usp=sharing\n",
            "Training Model: FAST-LSA-S\n",
            "Training Dataset: English\n",
            "Language: English\n",
            "Description: Trained on RTX3090\n",
            "Available Version: 1.6.3+\n",
            "Checkpoint File: fast_lsa_s_acc_84.9_f1_82.11.zip\n",
            "Author: H, Yang (yangheng@m.scnu.edu.cn)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Checkpoint Name: chinese\n",
            "id: https://drive.google.com/file/d/1B0RHazOCm2eOWLWExQkeapHr9d3OiZl7/view?usp=sharing\n",
            "Training Model: FAST-LCF-MDeBERTa\n",
            "Training Dataset: Chinese\n",
            "Language: Chinese\n",
            "Description: Trained on RTX3090\n",
            "Available Version: 1.8.2+\n",
            "Checkpoint File: fast_lcf_bert_Chinese_acc_97.11_f1_96.54.zip\n",
            "Author: H, Yang (yangheng@m.scnu.edu.cn)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Checkpoint Name: multilingual\n",
            "id: https://drive.google.com/file/d/15ls1hcGvk27UnfMsXZtk780h7tTBbNws/view?usp=sharing\n",
            "Training Model: FAST-LCF-Deberta\n",
            "Training Dataset: Multilingual\n",
            "Language: Multilingual\n",
            "Description: Trained on RTX3090\n",
            "Available Version: 1.8.2+\n",
            "Checkpoint File: fast_lcf_bert_Multilingual_acc_94.72_f1_90.07.zip\n",
            "Author: H, Yang (yangheng@m.scnu.edu.cn)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Checkpoint Name: multilingual2\n",
            "id: https://drive.google.com/file/d/1YCYKpEnff-DBUHd-8vWmgsnng5ZT_2cs/view?usp=sharing\n",
            "Training Model: FAST-LCF-Deberta\n",
            "Training Dataset: Multilingual\n",
            "Language: Multilingual\n",
            "Description: Trained on RTX3090\n",
            "Available Version: 1.10.5+\n",
            "Checkpoint File: fast_lsa_t_v2_Multilingual_acc_88.44_f1_82.66.zip\n",
            "Author: H, Yang (yangheng@m.scnu.edu.cn)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Checkpoint Name: HELP-WANTED\n",
            "id: \n",
            "Description: You can help us by sharing checkpoints (e.g. models trained on you own datasets) with community.\n",
            "Checkpoint File: PLEASE NOTE THAT THIS IS NOT A REAL CHECKPOINT!\n",
            "Available Version: \n",
            "----------------------------------------------------------------------------------------------------\n",
            "********** Available ATEPC model checkpoints for Version:1.15.5 (this version) **********\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Checkpoint Name: english\n",
            "id: https://drive.google.com/file/d/1_oBCLi_bjs4CxmEXfVIw8qZCmbJvr-PE/view?usp=sharing\n",
            "Training Model: FAST-LCFS-ATEPC\n",
            "Training Dataset: English\n",
            "Language: English\n",
            "Description: Trained on RTX3090, this checkpoint use bert-spc in ATEPC training\n",
            "Available Version: 1.8.4+\n",
            "Checkpoint File: fast_lcf_atepc_English_cdw_apcacc_85.03_apcf1_82.76_atef1_84.8.zip\n",
            "Author: H, Yang (yangheng@m.scnu.edu.cn)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Checkpoint Name: chinese\n",
            "id: https://drive.google.com/file/d/1wHlEeKbQg51LEgr-J353HQhyPgPDEMrp/view?usp=sharing\n",
            "Training Model: FAST-LCF-ATEPC\n",
            "Training Dataset: Chinese\n",
            "Language: Chinese\n",
            "Description: Trained on RTX3090 BERT-BASE-CHINESE\n",
            "Available Version: 1.8.4+\n",
            "Checkpoint File: fast_lcf_atepc_Chinese_cdw_apcacc_96.0_apcf1_94.96_atef1_91.34.zip\n",
            "Author: H, Yang (yangheng@m.scnu.edu.cn)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Checkpoint Name: multilingual\n",
            "id: https://drive.google.com/file/d/17r-dMGCUBKnWSQ-djN3MegASuJ7WLAwl/view?usp=sharing\n",
            "Training Model: FAST-LCF-ATEPC\n",
            "Training Dataset: ABSADatasets.Multilingual\n",
            "Language: Multilingual\n",
            "Description: Trained on RTX3090\n",
            "Available Version: 1.10.5+\n",
            "Checkpoint File: fast_lcf_atepc_Multilingual_cdw_apcacc_87.21_apcf1_81.53_atef1_82.82.zip\n",
            "Author: H, Yang (yangheng@m.scnu.edu.cn)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Checkpoint Name: multilingual-1.14.7\n",
            "id: https://drive.google.com/file/d/1gZRkcpSIqGfDacdTV4suqgRIfCbWgiHp/view?usp=sharing\n",
            "Training Model: FAST-LCF-ATEPC\n",
            "Training Dataset: ABSADatasets.Multilingual\n",
            "Language: Multilingual\n",
            "Description: Trained on RTX3090\n",
            "Available Version: 1.10.5+\n",
            "Checkpoint File: fast_lcf_atepc_Multilingual_cdw_apcacc_87.21_apcf1_81.53_atef1_82.82.zip\n",
            "Author: H, Yang (yangheng@m.scnu.edu.cn)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Checkpoint Name: multilingual4\n",
            "id: https://drive.google.com/file/d/1MAnpTiCHyjUDazel2kgHgaKXaDeE0NYW/view?usp=sharing\n",
            "Training Model: FAST-LCF-ATEPC\n",
            "Training Dataset: ABSADatasets.Multilingual\n",
            "Language: Multilingual\n",
            "Description: Trained on RTX3090\n",
            "Available Version: 1.10.5+\n",
            "Checkpoint File: fast_lcf_atepc_Multilingual_cdw_apcacc_88.96_apcf1_81.58_atef1_81.92.zip\n",
            "Author: H, Yang (yangheng@m.scnu.edu.cn)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Checkpoint Name: HELP-WANTED\n",
            "id: \n",
            "Description: You can help us by sharing checkpoints (e.g. models trained on you own datasets) with community.\n",
            "Checkpoint File: PLEASE NOTE THAT THIS IS NOT A REAL CHECKPOINT!\n",
            "Available Version: \n",
            "----------------------------------------------------------------------------------------------------\n",
            "********** Available TC model checkpoints for Version:1.15.5 (this version) **********\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Checkpoint Name: tc-sst2\n",
            "id: https://drive.google.com/file/d/1KgEB7MJ8bjrBiYdbtiojreeYegnUtq51/view?usp=sharing\n",
            "Training Model: TAD\n",
            "Training Dataset: SST2\n",
            "Language: English\n",
            "Description: Trained on RTX3090\n",
            "Available Version: 1.15+\n",
            "Checkpoint File: TC-SST2.zip\n",
            "Author: H, Yang (yangheng@m.scnu.edu.cn)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Checkpoint Name: tc-agnews10k\n",
            "id: https://drive.google.com/file/d/1JiRL19maSBiu9_1VBpP1gMwN8qkZsAtC/view?usp=sharing\n",
            "Training Model: TAD\n",
            "Training Dataset: AGNews\n",
            "Language: English\n",
            "Description: Trained on RTX3090\n",
            "Available Version: 1.15+\n",
            "Checkpoint File: TC-AGNews10K.zip\n",
            "Author: H, Yang (yangheng@m.scnu.edu.cn)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Checkpoint Name: tc-imdb10k\n",
            "id: https://drive.google.com/file/d/1TD0xyKKEfs_S0Ze0EmEb16Eq5pdukjN_/view?usp=sharing\n",
            "Training Model: TAD\n",
            "Training Dataset: IMDB10K\n",
            "Language: English\n",
            "Description: Trained on RTX3090\n",
            "Available Version: 1.15+\n",
            "Checkpoint File: TC-IMDB10K.zip\n",
            "Author: H, Yang (yangheng@m.scnu.edu.cn)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Checkpoint Name: HELP-WANTED\n",
            "id: \n",
            "Description: You can help us by sharing checkpoints (e.g. models trained on you own datasets) with community.\n",
            "Checkpoint File: PLEASE NOTE THAT THIS IS NOT A REAL CHECKPOINT!\n",
            "Available Version: \n",
            "----------------------------------------------------------------------------------------------------\n",
            "********** Available TAD model checkpoints for Version:1.15.5 (this version) **********\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Checkpoint Name: tad-sst2bae\n",
            "id: \n",
            "Training Model: TAD\n",
            "Training Dataset: SST2\n",
            "Language: English\n",
            "Description: Trained on RTX3090\n",
            "Available Version: 1.15+\n",
            "Checkpoint File: TAD-SST2BAE.zip\n",
            "Author: H, Yang (yangheng@m.scnu.edu.cn)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Checkpoint Name: tad-sst2pwws\n",
            "id: \n",
            "Training Model: TAD\n",
            "Training Dataset: AGNews\n",
            "Language: English\n",
            "Description: Trained on RTX3090\n",
            "Available Version: 1.15+\n",
            "Checkpoint File: TAD-SST2PWWS.zip\n",
            "Author: H, Yang (yangheng@m.scnu.edu.cn)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Checkpoint Name: tad-sst2textfooler\n",
            "id: \n",
            "Training Model: TAD\n",
            "Training Dataset: IMDB10K\n",
            "Language: English\n",
            "Description: Trained on RTX3090\n",
            "Available Version: 1.15+\n",
            "Checkpoint File: TAD-SST2TextFooler.zip\n",
            "Author: H, Yang (yangheng@m.scnu.edu.cn)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "There may be some checkpoints available for early versions of PyABSA, see ./checkpoints.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.10/dist-packages/pyabsa/functional/checkpoint/checkpoint_manager.py:259: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
            "  if max_ver == 'N.A.' or StrictVersion(min_ver) <= StrictVersion(__version__) <= StrictVersion(max_ver):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyabsa import ATEPCCheckpointManager\n",
        "\n",
        "aspect_extractor = ATEPCCheckpointManager.get_aspect_extractor(checkpoint='english',auto_device=False)"
      ],
      "metadata": {
        "id": "OWQFH5mXz5Hg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You can inference from a list of setences or a DatasetItem from PyABSA\n",
        "print(df)\n",
        "examples = df[\"Statements\"].tolist()\n",
        "inference_source = examples\n",
        "atepc_result = aspect_extractor.extract_aspect(inference_source=inference_source,  #\n",
        "                          pred_sentiment=True,  # Predict the sentiment of extracted aspect terms\n",
        "                          )\n"
      ],
      "metadata": {
        "id": "MegTWL1z0E7x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2986795c-ecc1-4e09-9531-56f77e39bf72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Statements\n",
            "0   I love the color and the performance is very ...\n",
            "1   I love the color and the performance is very ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The results of aspect term extraction have been saved in /content/atepc_inference.result.json\n",
            "Text: I love the <color:Positive> and the <performance:Positive> is very first .\n",
            "Text: I love the <color:Positive> and the <performance:Positive> is very first .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for result in atepc_result:\n",
        "    print(\"Sentence:\", result['sentence'])\n",
        "    print(\"Extracted Aspects:\", result['aspect'])\n",
        "    print(\"Sentiments:\", result['sentiment'])\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuvDnG35lEBA",
        "outputId": "d8141d67-8c33-4c95-f8c8-8834bebbfb96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: I love the <color:Positive> and the <performance:Positive> is very first .\n",
            "Extracted Aspects: ['color', 'performance']\n",
            "Sentiments: ['Positive', 'Positive']\n",
            "\n",
            "Sentence: I love the <color:Positive> and the <performance:Positive> is very first .\n",
            "Extracted Aspects: ['color', 'performance']\n",
            "Sentiments: ['Positive', 'Positive']\n",
            "\n"
          ]
        }
      ]
    }
  ]
}